{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "version": "3.6.4",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "mimetype": "text/x-python"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install openpyxl"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-24T04:43:19.513145Z",
     "iopub.execute_input": "2022-07-24T04:43:19.513592Z",
     "iopub.status.idle": "2022-07-24T04:43:28.857091Z",
     "shell.execute_reply.started": "2022-07-24T04:43:19.513551Z",
     "shell.execute_reply": "2022-07-24T04:43:28.855772Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_dataset(path):\n",
    "    datas= pd.read_excel(path)\n",
    "    data = []\n",
    "    for idx in datas.index:\n",
    "        sample = {}\n",
    "        x = datas.iloc[idx]\n",
    "        sample['document'] = x['text']\n",
    "        index = 0\n",
    "        for key in x.keys():\n",
    "            if x[key] == 1:\n",
    "                sample['label'] = index - 1\n",
    "            index += 1\n",
    "        data.append(sample)\n",
    "    return data"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2022-07-24T04:43:28.859936Z",
     "iopub.execute_input": "2022-07-24T04:43:28.860680Z",
     "iopub.status.idle": "2022-07-24T04:43:28.869383Z",
     "shell.execute_reply.started": "2022-07-24T04:43:28.860638Z",
     "shell.execute_reply": "2022-07-24T04:43:28.868373Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_data = load_dataset('../input/vntc-xlsx/train.xlsx')\n",
    "test_data = load_dataset('../input/vntc-xlsx/test.xlsx')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-24T04:43:28.871816Z",
     "iopub.execute_input": "2022-07-24T04:43:28.872705Z",
     "iopub.status.idle": "2022-07-24T04:44:09.121520Z",
     "shell.execute_reply.started": "2022-07-24T04:43:28.872665Z",
     "shell.execute_reply": "2022-07-24T04:44:09.120522Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, RobertaForSequenceClassification\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"vinai/phobert-base\", num_labels = 10)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-24T04:44:09.137971Z",
     "iopub.execute_input": "2022-07-24T04:44:09.138273Z",
     "iopub.status.idle": "2022-07-24T04:44:14.732233Z",
     "shell.execute_reply.started": "2022-07-24T04:44:09.138247Z",
     "shell.execute_reply": "2022-07-24T04:44:14.731366Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class VTCollator:\n",
    "    def __init__(self, tokenizer): \n",
    "        self.tokenizer = tokenizer\n",
    "    def __call__(self, batch):\n",
    "        encodings = {}\n",
    "        encodings['document'] = self.tokenizer([x['document'] for x in batch],padding=True, truncation=True,return_tensors='pt')\n",
    "        encodings['label'] = torch.tensor([x['label'] for x in batch])\n",
    "        return encodings"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-24T04:44:14.734320Z",
     "iopub.execute_input": "2022-07-24T04:44:14.734786Z",
     "iopub.status.idle": "2022-07-24T04:44:14.742047Z",
     "shell.execute_reply.started": "2022-07-24T04:44:14.734741Z",
     "shell.execute_reply": "2022-07-24T04:44:14.740851Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "from torch.utils.data import DataLoader\ncollator = VTCollator(tokenizer)\ntrain_dataloader = DataLoader(train_data, batch_size=2, shuffle = True, \n                              collate_fn=collator, num_workers=2)\n\ntest_dataloader = DataLoader(test_data, batch_size=2,\n                              collate_fn=collator, num_workers=2)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-24T04:44:14.744049Z",
     "iopub.execute_input": "2022-07-24T04:44:14.744428Z",
     "iopub.status.idle": "2022-07-24T04:44:14.769661Z",
     "shell.execute_reply.started": "2022-07-24T04:44:14.744392Z",
     "shell.execute_reply": "2022-07-24T04:44:14.768663Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "import torch\nimport torch.nn as nn",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-24T04:44:14.771426Z",
     "iopub.execute_input": "2022-07-24T04:44:14.771854Z",
     "iopub.status.idle": "2022-07-24T04:44:14.780098Z",
     "shell.execute_reply.started": "2022-07-24T04:44:14.771816Z",
     "shell.execute_reply": "2022-07-24T04:44:14.779152Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "class Network(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.roberta = model\n        \n    def forward(self, x):\n        outputs = self.roberta(**x)\n        k =  outputs.logits\n        return k",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-24T04:44:14.782505Z",
     "iopub.execute_input": "2022-07-24T04:44:14.783535Z",
     "iopub.status.idle": "2022-07-24T04:44:14.790535Z",
     "shell.execute_reply.started": "2022-07-24T04:44:14.783479Z",
     "shell.execute_reply": "2022-07-24T04:44:14.789427Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "import numpy as np\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-24T04:44:14.792357Z",
     "iopub.execute_input": "2022-07-24T04:44:14.792898Z",
     "iopub.status.idle": "2022-07-24T04:44:14.804208Z",
     "shell.execute_reply.started": "2022-07-24T04:44:14.792857Z",
     "shell.execute_reply": "2022-07-24T04:44:14.803204Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "from sklearn.metrics import accuracy_score, f1_score\ndef training(num):\n    # Training with Validation\n    model = Network()\n    model = model.to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.AdamW(model.parameters(), lr = 3e-5, eps = 1e-8)\n    epochs = 10\n    max_acc = -np.inf\n    count = 0\n    for e in range(epochs):\n        train_loss = 0.0\n        for batch in train_dataloader:\n            # Transfer Data to GPU if available\n            data_q, labels = batch['document'].to(device), batch['label'].to(device) \n            # Clear the gradients\n            optimizer.zero_grad()\n            # Forward Pass\n            target = model(data_q)\n            # Find the Loss\n            loss = criterion(target,labels)\n            # Calculate gradients\n            loss.backward()\n            # Update Weights\n            optimizer.step()\n            # Calculate Loss\n            train_loss += loss.item()\n        model.eval()\n        l = []\n        t = []\n        for batch in test_dataloader:\n            # Transfer Data to GPU if available\n            data_q = batch['document'].to(device)\n\n            labels = batch['label']\n            # Forward Pass\n            target = model(data_q)\n            # Find the Loss\n\n\n            lab = labels.numpy()\n            tar = np.argmax(target.cpu().detach().numpy(),axis=1)\n            l =  lab if len(l) == 0 else np.concatenate((l, lab))\n            t =  tar if len(t) == 0 else np.concatenate((t,tar))\n            \n        acc = accuracy_score(l,t)\n        f1 = f1_score(l,t,average='micro')\n        print(f'Epoch {e+1} \\t\\t Training Loss: {train_loss / len(train_dataloader)} \\t\\t Test Accuracy: {acc} \\t\\t F1 Score: {f1}')\n        if max_acc < acc:\n            print(f'Accuracy Increased({max_acc:.6f}--->{acc:.6f}) \\t Saving The Model')\n            max_acc = acc\n            # Saving State Dict\n            torch.save(model.state_dict(), f'saved_model_{num}.pth')\n            count = 0\n        count += 1\n        if count == 3:\n            break",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-24T04:44:14.807876Z",
     "iopub.execute_input": "2022-07-24T04:44:14.808278Z",
     "iopub.status.idle": "2022-07-24T04:44:14.822308Z",
     "shell.execute_reply.started": "2022-07-24T04:44:14.808251Z",
     "shell.execute_reply": "2022-07-24T04:44:14.821204Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "training(0)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-24T04:44:14.823959Z",
     "iopub.execute_input": "2022-07-24T04:44:14.824440Z",
     "iopub.status.idle": "2022-07-24T04:44:20.213407Z",
     "shell.execute_reply.started": "2022-07-24T04:44:14.824405Z",
     "shell.execute_reply": "2022-07-24T04:44:20.212147Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}